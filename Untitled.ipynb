{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Thomas\\Anaconda2\\lib\\site-packages\\IPython\\nbformat.py:13: ShimWarning: The `IPython.nbformat` package has been deprecated. You should import from nbformat instead.\n",
      "  \"You should import from nbformat instead.\", ShimWarning)\n",
      "C:\\Users\\Thomas\\Anaconda2\\lib\\site-packages\\nbformat\\current.py:19: UserWarning: nbformat.current is deprecated.\n",
      "\n",
      "- use nbformat for read/write/validate public API\n",
      "- use nbformat.vX directly to composing notebooks of a particular version\n",
      "\n",
      "  \"\"\")\n"
     ]
    },
    {
     "ename": "NotJSONError",
     "evalue": "Notebook does not appear to be JSON: 'import sys\\nimport os\\nimport numpy as ...",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotJSONError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-66fd38f069e6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mIPython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnbformat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrent\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnbf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mnb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnbf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test.py'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'py'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mnbf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test.ipynb'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ipynb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Thomas\\Anaconda2\\lib\\site-packages\\nbformat\\current.pyc\u001b[0m in \u001b[0;36mread\u001b[1;34m(fp, format, **kwargs)\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[0mThe\u001b[0m \u001b[0mnotebook\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mwas\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m     \"\"\"\n\u001b[1;32m--> 173\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mreads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Thomas\\Anaconda2\\lib\\site-packages\\nbformat\\current.pyc\u001b[0m in \u001b[0;36mreads\u001b[1;34m(s, format, version, **kwargs)\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'DEPRECATED'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'json'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[0m_warn_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m     \u001b[0mnb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreader_reads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m     \u001b[0mnb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Thomas\\Anaconda2\\lib\\site-packages\\nbformat\\reader.pyc\u001b[0m in \u001b[0;36mreads\u001b[1;34m(s, **kwargs)\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mversions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNBFormatError\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     \u001b[0mnb_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparse_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m     \u001b[1;33m(\u001b[0m\u001b[0mmajor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_version\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnb_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmajor\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mversions\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Thomas\\Anaconda2\\lib\\site-packages\\nbformat\\reader.pyc\u001b[0m in \u001b[0;36mparse_json\u001b[1;34m(s, **kwargs)\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;31m# Limit the error message to 80 characters.  Display whatever JSON will fit.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mNotJSONError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Notebook does not appear to be JSON: %r\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m77\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnb_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotJSONError\u001b[0m: Notebook does not appear to be JSON: 'import sys\\nimport os\\nimport numpy as ..."
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import itertools\n",
    "\n",
    "import cPickle as pickle\n",
    "\n",
    "import collections\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "import time as t\n",
    "\n",
    "\n",
    "\n",
    "def make_network(weight_dict, thresh=0):\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    Makes a NetworkX network from dictionary mapping pairs to weights\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    movie_net = nx.Graph()\n",
    "\n",
    "    for pair, weight in weight_dict.iteritems():\n",
    "\n",
    "        if \"Unknown\" in pair:\n",
    "\n",
    "            continue\n",
    "\n",
    "        if weight > thresh:\n",
    "\n",
    "            movie_net.add_node(pair[0])\n",
    "\n",
    "            movie_net.add_node(pair[1])\n",
    "\n",
    "            movie_net.add_edge(pair[0], pair[1], weight=weight)\n",
    "\n",
    "    return movie_net\n",
    "\n",
    "\n",
    "\n",
    "#normalize centrality so that the sum is unity\n",
    "\n",
    "def normalize(centrality):\n",
    "\n",
    "\tif sum(centrality.values()) !=0:\n",
    "\n",
    "\t\tnormfactor = 1./sum(centrality.values()) \n",
    "\n",
    "\t\tfor node in centrality:\n",
    "\n",
    "\t\t\tcentrality[node] *= normfactor\n",
    "\n",
    "\treturn centrality\n",
    "\n",
    "\n",
    "\n",
    "def statistics(G):\n",
    "\n",
    "\tprop = {}\n",
    "\n",
    "\t#simple graph properties\n",
    "\n",
    "\tprop['num_of_nodes'] = G.number_of_nodes()\n",
    "\n",
    "\tprop['num_of_edges'] = G.number_of_edges()\n",
    "\n",
    "\tprop['transitivity'] = nx.transitivity(G)\n",
    "\n",
    "\tprop['connectivity'] = nx.average_node_connectivity(G)\n",
    "\n",
    "\t\t\n",
    "\n",
    "\t#node measures and centralities\n",
    "\n",
    "\tprop['clustering'] = nx.clustering(G)\n",
    "\n",
    " \tprop['triangles'] = nx.triangles(G)\n",
    "\n",
    " \tprop['degree'] = normalize(nx.degree_centrality(G))\n",
    "\n",
    "\tprop['closeness'] = normalize(nx.degree_centrality(G))\n",
    "\n",
    "\tprop['betweenness'] = normalize(nx.betweenness_centrality(G))\n",
    "\n",
    "\n",
    "\n",
    "\t#things don't always make sense:\t\n",
    "\n",
    "\ttry:\n",
    "\n",
    "\t\tprop['assortativity'] = nx.degree_assortativity_coefficient(G)\n",
    "\n",
    "\texcept:\tpass\n",
    "\n",
    "\ttry:\n",
    "\n",
    "\t\tprop['diameter'] = nx.diameter(G)\n",
    "\n",
    "\texcept:\tpass\n",
    "\n",
    "\ttry:\t\t\n",
    "\n",
    "\t\tprop['eigenvector'] = normalize(nx.eigenvector_centrality(G))\n",
    "\n",
    "\texcept:\tpass\n",
    "\n",
    "\treturn prop\n",
    "\n",
    "\n",
    "\n",
    "DATAPATH = \"/Users/Thomas/Desktop/SFI/project/movie/movie_screenshares/raw_data/\"\n",
    "\n",
    "\n",
    "\n",
    "#generate movies\n",
    "\n",
    "movies = {}\n",
    "\n",
    "for fn in os.listdir(DATAPATH):\n",
    "\n",
    "    with open(DATAPATH +fn) as file:\n",
    "\n",
    "        try:\n",
    "\n",
    "            movies[fn.split(\".\")[0]] = pickle.load(file)\n",
    "\n",
    "        except:\n",
    "\n",
    "            continue\n",
    "\n",
    "\n",
    "\n",
    "#character gender id\n",
    "\n",
    "gender_dic = {}\n",
    "\n",
    "with open('gender.txt','rb') as f:\n",
    "\n",
    "\tfor lines in f:\n",
    "\n",
    "\t\tkey,val = lines.split()[0].split(',')[0],lines.split()[0].split(',')[2]\n",
    "\n",
    "\t\tgender_dic[key] = val \n",
    "\n",
    "gender_dic[-1] = 'Unkonwn'\t\t\n",
    "\n",
    "\n",
    "\n",
    "#generate networks and statistics\t\n",
    "\n",
    "networks = {}\n",
    "\n",
    "net_stat = {}\n",
    "\n",
    "for movie, movie_info in movies.iteritems():\n",
    "\n",
    "    networks[movie] = make_network(movie_info[\"screen_share\"])\n",
    "\n",
    "    net_stat[movie] = {}\n",
    "\n",
    "    #keep useful infos\n",
    "\n",
    "    node_list = networks[movie].nodes()\n",
    "\n",
    "    personid = [-1]*len(node_list)\n",
    "\n",
    "    for i in range(len(node_list)):\n",
    "\n",
    "    \tfor act in movie_info['people']['cast']:\n",
    "\n",
    "\t\t\ttry:\n",
    "\n",
    "\t\t\t\tif node_list[i] == act['characterName']:\n",
    "\n",
    "\t\t\t\t\tpersonid[i] = act['personId']\n",
    "\n",
    "\t\t\t\t\tbreak\n",
    "\n",
    "\t\t\texcept:\t\n",
    "\n",
    "\t\t\t\tbreak\n",
    "\n",
    "\tnet_stat[movie]['personid'] = personid\n",
    "\n",
    "    net_stat[movie]['gender'] =  [gender_dic[key] for key in personid]\n",
    "\n",
    "    net_stat[movie]['year'] = movie_info['metadata']['releaseYear']\n",
    "\n",
    "    \n",
    "\n",
    "#getting various network measures\n",
    "\n",
    "for movie,movie_net in networks.iteritems():\n",
    "\n",
    "\tG = movie_net\n",
    "\n",
    "\t#simple graph properties\n",
    "\n",
    "\tnet_stat[movie]['num_of_nodes'] = G.number_of_nodes()\n",
    "\n",
    "\tnet_stat[movie]['num_of_edges'] = G.number_of_edges()\n",
    "\n",
    "\tnet_stat[movie]['transitivity'] = nx.transitivity(G)\n",
    "\n",
    "\tnet_stat[movie]['connectivity'] = nx.average_node_connectivity(G)\n",
    "\n",
    "\t\t\n",
    "\n",
    "\t#node measures and centralities\n",
    "\n",
    "\tnet_stat[movie]['clustering'] = nx.clustering(G)\n",
    "\n",
    "\tnet_stat[movie]['triangles'] = nx.triangles(G)\n",
    "\n",
    "\tnet_stat[movie]['degree'] = normalize(nx.degree_centrality(G))\n",
    "\n",
    "\tnet_stat[movie]['closeness'] = normalize(nx.degree_centrality(G))\n",
    "\n",
    "\tnet_stat[movie]['betweenness'] = normalize(nx.betweenness_centrality(G))\n",
    "\n",
    "\n",
    "\n",
    "\t#things don't always make sense:\t\n",
    "\n",
    "\ttry:\n",
    "\n",
    "\t\tnet_stat[movie]['assortativity'] = nx.degree_assortativity_coefficient(G)\n",
    "\n",
    "\texcept:\tpass\n",
    "\n",
    "\ttry:\n",
    "\n",
    "\t\tnet_stat[movie]['diameter'] = nx.diameter(G)\n",
    "\n",
    "\texcept:\tpass\n",
    "\n",
    "\ttry:\t\t\n",
    "\n",
    "\t\tnet_stat[movie]['eigenvector'] = normalize(nx.eigenvector_centrality(G))\n",
    "\n",
    "\texcept:\tpass\n",
    "\n",
    "\tf = open(SAVEPATH +movie+'_stats'+'.pkl','wb')\n",
    "\n",
    "\tpickle.dump(net_stat[movie],f)\n",
    "\n",
    "\tf.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
